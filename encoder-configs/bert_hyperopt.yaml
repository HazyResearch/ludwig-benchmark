input_features:
  - 
    preprocessing:
      word_tokenizer: hf_tokenizer
      pretrained_model_name_or_path: bert-base-uncased

training:
  batch_size: 16
  
parameters:
  input_features.name.encoder: bert
  input_features.name.reduce_output: 
    type: category
    values: [cls_pooled, sum, avg]
  output_features.name.fc_layers:
    type: category
    values: [
      [{fc_size: 512}, {fc_size: 256}],
      [{fc_size: 512}],
      [{fc_size: 256}]
    ]
